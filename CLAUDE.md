# Databricks Apps + Streamlit ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

Unity Catalogã®ãƒ‡ãƒ¼ã‚¿ã‚’å¯è¦–åŒ–ã™ã‚‹Streamlitãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã€‚

## æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- Python 3.11
- Streamlit
- Databricks SDK (databricks-sdk)
- Databricks SQL Connector (databricks-sql-connector)

## é–‹ç™ºã‚³ãƒãƒ³ãƒ‰

```bash
# ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ(åˆå›ã¯--prepare-environmentã§ä»®æƒ³ç’°å¢ƒã‚’è‡ªå‹•ä½œæˆ)
databricks apps run-local --prepare-environment

# ç’°å¢ƒå¤‰æ•°ã‚’è¿½åŠ ã—ã¦ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œ(valueFromã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§è§£æ±ºã§ããªã„ãŸã‚--envã§æ¸¡ã™)
databricks apps run-local --prepare-environment --env DATABRICKS_WAREHOUSE_ID=xxx

# ãƒ‡ãƒ—ãƒ­ã‚¤
databricks apps deploy <app-name>

# ãƒ­ã‚°ç¢ºèª
databricks apps logs <app-name>
```

**é‡è¦**: 
- `--prepare-environment`ã‚’ä»˜ã‘ãªã„ã¨ã€streamlitç­‰ã®ä¾å­˜é–¢ä¿‚ãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„çŠ¶æ…‹ã§å®Ÿè¡Œã•ã‚Œã€`executable file not found`ã‚¨ãƒ©ãƒ¼ã«ãªã‚‹
- app.yamlã§`valueFrom`ã‚’ä½¿ç”¨ã—ã¦ã„ã‚‹ç’°å¢ƒå¤‰æ•°ã¯ã€ãƒ­ãƒ¼ã‚«ãƒ«å®Ÿè¡Œæ™‚ã«`--env`ãƒ•ãƒ©ã‚°ã§æ˜ç¤ºçš„ã«æ¸¡ã™å¿…è¦ãŒã‚ã‚‹

## app.yaml ã®ãƒ«ãƒ¼ãƒ«

### command ã¯å¿…ãšãƒªã‚¹ãƒˆå½¢å¼

```yaml
# âœ… æ­£ã—ã„
command:
  - streamlit
  - run
  - app.py
  - --server.port=8000
  - --server.address=0.0.0.0

# âŒ é–“é•ã„
command: "streamlit run app.py"
```

### env ã¯ name/value ãƒšã‚¢ã®ãƒªã‚¹ãƒˆ

```yaml
# âœ… æ­£ã—ã„
env:
  - name: DATABRICKS_WAREHOUSE_ID
    valueFrom: sql-warehouse-id
  - name: LOG_LEVEL
    value: INFO

# âŒ é–“é•ã„
env:
  DATABRICKS_WAREHOUSE_ID: "xxx"
```

### valueFrom vs value ã®ä½¿ã„åˆ†ã‘

| ãƒ‘ã‚¿ãƒ¼ãƒ³ | ç”¨é€” |
|----------|------|
| `valueFrom: sql-warehouse-id` | SQL Warehouse ID |
| `valueFrom: serving-endpoint-name` | Model Serving ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå |
| `value: "å›ºå®šå€¤"` | å›ºå®šã®è¨­å®šå€¤ |

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è¦ä»¶

### SQLã‚¯ã‚¨ãƒªã¯å¿…ãšãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿åŒ–

```python
# âœ… æ­£ã—ã„
cursor.execute(
    "SELECT * FROM catalog.schema.table WHERE id = :id",
    {"id": user_input}
)

# âŒ é–“é•ã„ï¼ˆSQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ã®å±é™ºï¼‰
cursor.execute(f"SELECT * FROM table WHERE id = {user_input}")
```

### èªè¨¼æƒ…å ±ã‚’ãƒãƒ¼ãƒ‰ã‚³ãƒ¼ãƒ‰ã—ãªã„

```python
# âœ… æ­£ã—ã„ - SDKã®è‡ªå‹•èªè¨¼ã‚’ä½¿ç”¨
from databricks.sdk import WorkspaceClient
w = WorkspaceClient()

# âŒ é–“é•ã„
token = "dapi_xxxxxxxxxxxxx"
```

## Streamlit ã®ãƒ™ã‚¹ãƒˆãƒ—ãƒ©ã‚¯ãƒ†ã‚£ã‚¹

### st.set_page_config() ã¯æœ€åˆã«å‘¼ã³å‡ºã™

```python
import streamlit as st

# å¿…ãšæœ€åˆã«å‘¼ã³å‡ºã™
st.set_page_config(
    page_title="UC Browser",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ä»–ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã‚„ã‚³ãƒ¼ãƒ‰ã¯ã“ã®å¾Œ
```

### æ¥ç¶šã¯ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã™ã‚‹

```python
@st.cache_resource
def get_workspace_client():
    return WorkspaceClient()

@st.cache_resource
def get_sql_connection():
    return sql.connect(...)
```

## requirements.txt ã®ãƒ«ãƒ¼ãƒ«

ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚’å¿…ãšå›ºå®šã™ã‚‹:

```txt
streamlit==1.45.0
databricks-sdk==0.55.0
databricks-sql-connector==4.0.0
pandas==2.2.3
numpy>=1.26.0,<2.0.0
```

## ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
project/
â”œâ”€â”€ CLAUDE.md           # ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ app.yaml            # Databricks Appsè¨­å®š
â”œâ”€â”€ app.py              # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ requirements.txt    # ä¾å­˜é–¢ä¿‚
â””â”€â”€ README.md           # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜
```

## ã‚ˆãã‚ã‚‹ã‚¨ãƒ©ãƒ¼ã¨å¯¾å‡¦æ³•

| ã‚¨ãƒ©ãƒ¼ | åŸå›  | å¯¾å‡¦æ³• |
|-------|------|--------|
| `streamlit: executable file not found` | ä¾å­˜é–¢ä¿‚æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | `--prepare-environment`ã‚’ä»˜ã‘ã¦å®Ÿè¡Œ |
| `valueFrom property and can't be resolved locally` | valueFromã¯ãƒ­ãƒ¼ã‚«ãƒ«ã§è§£æ±ºä¸å¯ | `--env VAR_NAME=value`ã§ç’°å¢ƒå¤‰æ•°ã‚’æ¸¡ã™ |
| `YAML parse error` | app.yamlã®æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ | command/envã®å½¢å¼ã‚’ç¢ºèª |
| `ModuleNotFoundError` | ä¾å­˜é–¢ä¿‚ä¸è¶³ | requirements.txtã‚’ç¢ºèª |
| `Connection refused` | ãƒãƒ¼ãƒˆä¸ä¸€è‡´ | --server.port=8000ã‚’ç¢ºèª |
| `401 Unauthorized` | èªè¨¼ã‚¨ãƒ©ãƒ¼ | SDKè‡ªå‹•èªè¨¼ã®è¨­å®šã‚’ç¢ºèª |
